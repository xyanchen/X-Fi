{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import yaml\n",
    "from evaluate import error\n",
    "import time\n",
    "import re\n",
    "from syn_DI_dataset import make_dataset, make_dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loda Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['depth', 'wifi-csi']\n",
      "S02 ['A01', 'A02', 'A03', 'A04', 'A06', 'A08', 'A09', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A26']\n",
      "S03 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A17', 'A18', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S05 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A19', 'A20', 'A21', 'A24', 'A25']\n",
      "S06 ['A01', 'A03', 'A04', 'A06', 'A07', 'A08', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A18', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S08 ['A01', 'A02', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A13', 'A14', 'A17', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S09 ['A01', 'A07', 'A08', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A17', 'A18', 'A20', 'A21', 'A24', 'A25', 'A27']\n",
      "S11 ['A01', 'A02', 'A03', 'A05', 'A06', 'A08', 'A10', 'A11', 'A12', 'A13', 'A16', 'A17', 'A18', 'A19', 'A21', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S12 ['A01', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A14', 'A15', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S13 ['A01', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A14', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A25', 'A26', 'A27']\n",
      "S14 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A13', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26']\n",
      "S15 ['A01', 'A02', 'A03', 'A04', 'A05', 'A07', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S16 ['A01', 'A04', 'A05', 'A06', 'A08', 'A09', 'A10', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A19', 'A20', 'A23', 'A24', 'A27']\n",
      "S17 ['A01', 'A02', 'A03', 'A04', 'A05', 'A08', 'A09', 'A10', 'A11', 'A13', 'A16', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S18 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A20', 'A21', 'A22', 'A23', 'A24', 'A26']\n",
      "S19 ['A01', 'A02', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A24', 'A25', 'A26', 'A27']\n",
      "S21 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A08', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A19', 'A20', 'A24', 'A25', 'A26', 'A27']\n",
      "S23 ['A01', 'A02', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A11', 'A12', 'A14', 'A16', 'A17', 'A19', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S25 ['A01', 'A02', 'A03', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A16', 'A17', 'A18', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S26 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A09', 'A10', 'A13', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A25', 'A27']\n",
      "S27 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A10', 'A11', 'A12', 'A13', 'A16', 'A17', 'A18', 'A19', 'A20', 'A22', 'A23', 'A25']\n",
      "S28 ['A01', 'A02', 'A03', 'A04', 'A05', 'A07', 'A08', 'A09', 'A11', 'A14', 'A15', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A25', 'A26', 'A27']\n",
      "S29 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A09', 'A12', 'A13', 'A14', 'A17', 'A18', 'A19', 'A20', 'A22', 'A23', 'A24', 'A25', 'A27']\n",
      "S30 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A21', 'A22', 'A24', 'A25', 'A26', 'A27']\n",
      "S31 ['A01', 'A02', 'A03', 'A04', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S32 ['A01', 'A02', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A19', 'A22', 'A25', 'A26', 'A27']\n",
      "S33 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26']\n",
      "S34 ['A01', 'A02', 'A03', 'A05', 'A06', 'A07', 'A08', 'A09', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S35 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A15', 'A16', 'A17', 'A18', 'A21', 'A23', 'A24', 'A26', 'A27']\n",
      "S36 ['A01', 'A02', 'A04', 'A05', 'A09', 'A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A23', 'A24', 'A26', 'A27']\n",
      "S37 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A24', 'A25', 'A26', 'A27']\n",
      "S38 ['A01', 'A03', 'A04', 'A05', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S40 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A27']\n",
      "S04 ['A02', 'A03', 'A06', 'A07', 'A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A26', 'A27']\n",
      "S07 ['A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26']\n",
      "S20 ['A02', 'A03', 'A05', 'A06', 'A07', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A21', 'A22', 'A23', 'A25', 'A26']\n",
      "S22 ['A02', 'A03', 'A05', 'A06', 'A07', 'A08', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S24 ['A02', 'A03', 'A04', 'A06', 'A07', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A27']\n",
      "S39 ['A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A20', 'A22', 'A23', 'A25', 'A26', 'A27']\n",
      "S01 ['A03', 'A06', 'A07', 'A08', 'A09', 'A10', 'A12', 'A13', 'A14', 'A15', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A24', 'A26', 'A27']\n",
      "S10 ['A03', 'A04', 'A08', 'A09', 'A10', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A23', 'A25', 'A26', 'A27']\n",
      "/n\n",
      "['depth', 'wifi-csi']\n",
      "S01 ['A01', 'A02', 'A04', 'A05', 'A11', 'A16', 'A23', 'A25']\n",
      "S04 ['A01', 'A04', 'A05', 'A08', 'A09', 'A13', 'A25']\n",
      "S07 ['A01', 'A13', 'A18', 'A27']\n",
      "S10 ['A01', 'A02', 'A05', 'A06', 'A07', 'A11', 'A21', 'A22', 'A24']\n",
      "S20 ['A01', 'A04', 'A08', 'A09', 'A19', 'A20', 'A24', 'A27']\n",
      "S22 ['A01', 'A04', 'A09']\n",
      "S24 ['A01', 'A05', 'A08', 'A25', 'A26']\n",
      "S39 ['A01', 'A10', 'A19', 'A21', 'A24']\n",
      "S06 ['A02', 'A05', 'A09', 'A16', 'A17', 'A19', 'A20']\n",
      "S09 ['A02', 'A03', 'A04', 'A05', 'A06', 'A09', 'A16', 'A19', 'A22', 'A23', 'A26']\n",
      "S12 ['A02', 'A03', 'A13', 'A16']\n",
      "S13 ['A02', 'A12', 'A13', 'A15', 'A16', 'A24']\n",
      "S16 ['A02', 'A03', 'A07', 'A11', 'A18', 'A21', 'A22', 'A25', 'A26']\n",
      "S38 ['A02', 'A06', 'A17', 'A18']\n",
      "S08 ['A03', 'A12', 'A15', 'A16', 'A18']\n",
      "S19 ['A03', 'A14', 'A23']\n",
      "S23 ['A03', 'A10', 'A13', 'A15', 'A18', 'A20']\n",
      "S32 ['A03', 'A17', 'A18', 'A20', 'A21', 'A23', 'A24']\n",
      "S36 ['A03', 'A06', 'A07', 'A08', 'A13', 'A21', 'A22', 'A25']\n",
      "S11 ['A04', 'A07', 'A09', 'A14', 'A15', 'A20', 'A22']\n",
      "S25 ['A04', 'A15', 'A19']\n",
      "S34 ['A04', 'A10', 'A11', 'A12']\n",
      "S02 ['A05', 'A07', 'A10', 'A17', 'A25', 'A27']\n",
      "S31 ['A05', 'A06', 'A17']\n",
      "S15 ['A06', 'A08']\n",
      "S17 ['A06', 'A07', 'A12', 'A14', 'A15', 'A17']\n",
      "S28 ['A06', 'A10', 'A12', 'A13', 'A16', 'A24']\n",
      "S21 ['A07', 'A09', 'A18', 'A21', 'A22', 'A23']\n",
      "S26 ['A07', 'A08', 'A11', 'A12', 'A14', 'A24', 'A26']\n",
      "S05 ['A08', 'A17', 'A18', 'A22', 'A23', 'A26', 'A27']\n",
      "S29 ['A08', 'A10', 'A11', 'A15', 'A16', 'A21', 'A26']\n",
      "S27 ['A09', 'A14', 'A15', 'A21', 'A24', 'A26', 'A27']\n",
      "S30 ['A10', 'A11', 'A20', 'A23']\n",
      "S40 ['A10', 'A26']\n",
      "S37 ['A11', 'A23']\n",
      "S14 ['A12', 'A14', 'A27']\n",
      "S18 ['A12', 'A19', 'A25', 'A27']\n",
      "S03 ['A13', 'A14', 'A19', 'A20']\n",
      "S35 ['A14', 'A19', 'A20', 'A22', 'A25']\n",
      "S33 ['A17', 'A27']\n"
     ]
    }
   ],
   "source": [
    "dataset_root = 'd:\\Data\\My_MMFi_Data\\MMFi_Dataset'\n",
    "with open('config.yaml', 'r') as fd:\n",
    "    config = yaml.load(fd, Loader=yaml.FullLoader)\n",
    "\n",
    "train_dataset, val_dataset = make_dataset(dataset_root, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    Padds batch of variable length\n",
    "\n",
    "    note: it converts things ToTensor manually here since the ToTensor transform\n",
    "    assume it takes in images rather than arbitrary tensors.\n",
    "\n",
    "    dict_keys(['modality', 'scene', 'subject', 'action', 'idx', 'output', \n",
    "    'input_rgb', 'input_depth', 'input_lidar', 'input_mmwave'])\n",
    "    '''\n",
    "    ## get sequence lengths\n",
    "    # for t in batch:\n",
    "    #     print(t.keys())\n",
    "    #     print(a)\n",
    "    # #     # print(t[0].shape,t[1].shape)\n",
    "    kpts = []\n",
    "    [kpts.append(np.array(t['output'])) for t in batch]\n",
    "    kpts = torch.FloatTensor(np.array(kpts))\n",
    "\n",
    "    # lengths = torch.tensor([t['input_mmwave'].shape[0] for t in batch ])\n",
    "\n",
    "    # # rgb\n",
    "    # rgb_data = np.array([(t['input_rgb']) for t in batch ])\n",
    "    # rgb_data = torch.FloatTensor(rgb_data).permute(0,3,1,2)\n",
    "\n",
    "    # depth\n",
    "    depth_data = np.array([(t['input_depth']) for t in batch ])\n",
    "    depth_data = torch.FloatTensor(depth_data).permute(0,3,1,2)\n",
    "\n",
    "    # # mmwave\n",
    "    # ## padd\n",
    "    # mmwave_data = [torch.Tensor(t['input_mmwave']) for t in batch ]\n",
    "    # mmwave_data = torch.nn.utils.rnn.pad_sequence(mmwave_data)\n",
    "    # ## compute mask\n",
    "    # mmwave_data = mmwave_data.permute(1,0,2)\n",
    "\n",
    "    # # lidar\n",
    "    # ## padd\n",
    "    # lidar_data = [torch.Tensor(t['input_lidar']) for t in batch ]\n",
    "    # lidar_data = torch.nn.utils.rnn.pad_sequence(lidar_data)\n",
    "    # ## compute mask\n",
    "    # lidar_data = lidar_data.permute(1,0,2)\n",
    "\n",
    "    # wifi-csi\n",
    "    wifi_data = np.array([(t['input_wifi-csi']) for t in batch ])\n",
    "    wifi_data = torch.FloatTensor(wifi_data)\n",
    "    \"要改\"\n",
    "    exist_list = [False, True, False, False, True]\n",
    "\n",
    "    # return rgb_data, depth_data, lidar_data, mmwave_data, wifi_data, kpts, modality_list\n",
    "    return depth_data, wifi_data, kpts, exist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_generator = torch.manual_seed(config['init_rand_seed'])\n",
    "train_loader = make_dataloader(train_dataset, is_training=True, generator=rng_generator, **config['loader'], collate_fn = collate_fn_padd)\n",
    "val_loader = make_dataloader(val_dataset, is_training=False, generator=rng_generator, **config['loader'], collate_fn = collate_fn_padd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12991.5\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader.dataset)/16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "............................................................................................\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "............................................................................................\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "torch.Size([16, 3, 480, 640]) torch.Size([16, 3, 114, 10]) torch.Size([16, 17, 3])\n",
      "[False, True, False, False, True]\n",
      "............................................................................................\n"
     ]
    }
   ],
   "source": [
    "avg_time = 0\n",
    "for epoch in range(3):\n",
    "    # random.seed(config['modality_existances']['train_random_seed'])\n",
    "    i= 0\n",
    "    for data in val_loader:\n",
    "        # start_time = time.time()\n",
    "        input_1, input2_, kpts, exist_list = data\n",
    "        # epoch_time = time.time() - start_time\n",
    "        # print(rgb_data[0].shape, depth_data[0].shape, lidar_data[0].shape, mmwave_data[0].shape, wifi_data[0].shape,kpts.shape, lengths.shape)\n",
    "        print(input_1.shape, input2_.shape, kpts.shape)\n",
    "        # print('epoch_time: ', epoch_time)\n",
    "        # avg_time += epoch_time\n",
    "        # print(rgb_data, depth_data, lidar_data, mmwave_data, wifi_data, kpts, modality_list)\n",
    "        print(exist_list)\n",
    "        i += 1\n",
    "        if i > 1:\n",
    "            print('............................................................................................')\n",
    "            break\n",
    "    # print('tot_time: ', avg_time)\n",
    "    # print('avg_time: ', avg_time / (i+1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dual_model(\n",
       "  (feature_extractor): Dual_feature_extrator(\n",
       "    (depth_extractor): depth_feature_extractor(\n",
       "      (part): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(3, 3, kernel_size=(14, 14), stride=(2, 2))\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(3, 3, kernel_size=(5, 56), stride=(1, 1))\n",
       "          (3): ReLU()\n",
       "          (4): Conv2d(3, 3, kernel_size=(5, 23), stride=(1, 1))\n",
       "          (5): ReLU()\n",
       "          (6): Conv2d(3, 16, kernel_size=(3, 14), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2d(16, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "        (4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (5): Sequential(\n",
       "          (0): Block(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Block(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (i_downsample): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Block(\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (i_downsample): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Block(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (i_downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (csi_extractor): csi_feature_extractor(\n",
       "      (part): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (4): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (5): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (regression_head): regression_Head(\n",
       "    (0): Reduce('b n e -> b e', 'mean')\n",
       "    (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Linear(in_features=512, out_features=51, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'model without pos encoding'\n",
    "from baseline_model import dual_model\n",
    "\n",
    "# model = model(['RGB'])\n",
    "model = dual_model(['Depth','Wifi'])\n",
    "model.cuda()\n",
    "\n",
    "# rgb_data = torch.randn(16, 3, 480, 640).cuda()\n",
    "# # depth_data = torch.randn(16, 3, 480, 640).cuda()\n",
    "# # mmwave_data = torch.randn(16, 67, 5).cuda()\n",
    "# # lidar_data = torch.randn(16, 1432, 3).cuda()\n",
    "# wifi_data = torch.randn(16, 3, 114, 10).cuda()\n",
    "# modality_list = [True, False, False, False, True]\n",
    "# # modality_list = [True, True, True, True, True]\n",
    "\n",
    "\n",
    "# # out = model(rgb_data, depth_data,  mmwave_data, lidar_data, wifi_data, modality_list)\n",
    "# out = model(rgb_data, wifi_data, modality_list)\n",
    "# print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modality_invariant_model(\n",
       "  (feature_extractor): feature_extrator(\n",
       "    (rgb_extractor): rgb_feature_extractor(\n",
       "      (part): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(3, 3, kernel_size=(14, 14), stride=(2, 2))\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(3, 3, kernel_size=(5, 56), stride=(1, 1))\n",
       "          (3): ReLU()\n",
       "          (4): Conv2d(3, 3, kernel_size=(5, 23), stride=(1, 1))\n",
       "          (5): ReLU()\n",
       "          (6): Conv2d(3, 16, kernel_size=(3, 14), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2d(16, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "        (4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (5): Sequential(\n",
       "          (0): Block(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Block(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (i_downsample): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Block(\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (i_downsample): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Block(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (i_downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (depth_extractor): depth_feature_extractor(\n",
       "      (part): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(3, 3, kernel_size=(14, 14), stride=(2, 2))\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(3, 3, kernel_size=(5, 56), stride=(1, 1))\n",
       "          (3): ReLU()\n",
       "          (4): Conv2d(3, 3, kernel_size=(5, 23), stride=(1, 1))\n",
       "          (5): ReLU()\n",
       "          (6): Conv2d(3, 16, kernel_size=(3, 14), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2d(16, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (3): ReLU()\n",
       "        (4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (5): Sequential(\n",
       "          (0): Block(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Block(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (i_downsample): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Block(\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (i_downsample): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Block(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (i_downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (batch_norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mmwave_extractor): mmwave_feature_extractor(\n",
       "      (part): Sequential(\n",
       "        (0): Backbone(\n",
       "          (fc1): Sequential(\n",
       "            (0): Linear(in_features=5, out_features=32, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "          (transformer1): TransformerBlock(\n",
       "            (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
       "            (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
       "            (fc_delta): Sequential(\n",
       "              (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (fc_gamma): Sequential(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): ReLU()\n",
       "              (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (w_qs): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (w_ks): Linear(in_features=128, out_features=128, bias=False)\n",
       "            (w_vs): Linear(in_features=128, out_features=128, bias=False)\n",
       "          )\n",
       "          (transition_downs): ModuleList(\n",
       "            (0): TransitionDown(\n",
       "              (conv1): Sequential(\n",
       "                (0): Conv1d(35, 64, kernel_size=(1,), stride=(1,))\n",
       "                (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (conv2): Sequential(\n",
       "                (0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "                (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (1): TransitionDown(\n",
       "              (conv1): Sequential(\n",
       "                (0): Conv1d(67, 128, kernel_size=(1,), stride=(1,))\n",
       "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (conv2): Sequential(\n",
       "                (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "                (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (2): TransitionDown(\n",
       "              (conv1): Sequential(\n",
       "                (0): Conv1d(131, 256, kernel_size=(1,), stride=(1,))\n",
       "                (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (conv2): Sequential(\n",
       "                (0): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "                (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "            )\n",
       "            (3): TransitionDown(\n",
       "              (conv1): Sequential(\n",
       "                (0): Conv1d(259, 512, kernel_size=(1,), stride=(1,))\n",
       "                (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "              (conv2): Sequential(\n",
       "                (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "                (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (transformers): ModuleList(\n",
       "            (0): TransformerBlock(\n",
       "              (fc1): Linear(in_features=64, out_features=128, bias=True)\n",
       "              (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "              (fc_delta): Sequential(\n",
       "                (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (fc_gamma): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (w_qs): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (w_ks): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (w_vs): Linear(in_features=128, out_features=128, bias=False)\n",
       "            )\n",
       "            (1): TransformerBlock(\n",
       "              (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (fc_delta): Sequential(\n",
       "                (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (fc_gamma): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (w_qs): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (w_ks): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (w_vs): Linear(in_features=128, out_features=128, bias=False)\n",
       "            )\n",
       "            (2): TransformerBlock(\n",
       "              (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (fc2): Linear(in_features=128, out_features=256, bias=True)\n",
       "              (fc_delta): Sequential(\n",
       "                (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (fc_gamma): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (w_qs): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (w_ks): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (w_vs): Linear(in_features=128, out_features=128, bias=False)\n",
       "            )\n",
       "            (3): TransformerBlock(\n",
       "              (fc1): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (fc2): Linear(in_features=128, out_features=512, bias=True)\n",
       "              (fc_delta): Sequential(\n",
       "                (0): Linear(in_features=3, out_features=128, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (fc_gamma): Sequential(\n",
       "                (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                (1): ReLU()\n",
       "                (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (w_qs): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (w_ks): Linear(in_features=128, out_features=128, bias=False)\n",
       "              (w_vs): Linear(in_features=128, out_features=128, bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lidar_extractor): lidar_feature_extractor(\n",
       "      (fc1): Sequential(\n",
       "        (0): Linear(in_features=3, out_features=32, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (transformer1): TransformerBlock(\n",
       "        (fc1): Linear(in_features=32, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=32, bias=True)\n",
       "        (fc_delta): Sequential(\n",
       "          (0): Linear(in_features=3, out_features=512, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (fc_gamma): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "      )\n",
       "      (transition_downs): ModuleList(\n",
       "        (0): TransitionDown(\n",
       "          (sa): PointNetSetAbstraction(\n",
       "            (mlp_convs): ModuleList(\n",
       "              (0): Conv2d(35, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (mlp_bns): ModuleList(\n",
       "              (0-1): 2 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (transformers): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (fc1): Linear(in_features=64, out_features=512, bias=True)\n",
       "          (fc2): Linear(in_features=512, out_features=64, bias=True)\n",
       "          (fc_delta): Sequential(\n",
       "            (0): Linear(in_features=3, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (fc_gamma): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (w_qs): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_ks): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (w_vs): Linear(in_features=512, out_features=512, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (csi_extractor): csi_feature_extractor(\n",
       "      (part): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (3): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (4): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (5): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): BasicBlock(\n",
       "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (2): BasicBlock(\n",
       "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear_projector): linear_projector(\n",
       "    (rgb_linear_projection): Sequential(\n",
       "      (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=49, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "    )\n",
       "    (depth_linear_projection): Sequential(\n",
       "      (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=49, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "    )\n",
       "    (mmwave_linear_projection): Sequential(\n",
       "      (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (lidar_linear_projection): Sequential(\n",
       "      (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "    )\n",
       "    (csi_linear_projection): Sequential(\n",
       "      (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=68, out_features=32, bias=True)\n",
       "      (4): ReLU()\n",
       "    )\n",
       "    (pos_enc_layer): Sequential(\n",
       "      (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vit): ViT(\n",
       "    (0): TransformerEncoder(\n",
       "      (0): TransformerEncoderBlock(\n",
       "        (0): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): MultiHeadAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (att_drop): Dropout(p=0.0, inplace=False)\n",
       "              (projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForwardBlock(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): TransformerEncoderBlock(\n",
       "        (0): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): MultiHeadAttention(\n",
       "              (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "              (att_drop): Dropout(p=0.0, inplace=False)\n",
       "              (projection): Linear(in_features=512, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualAdd(\n",
       "          (fn): Sequential(\n",
       "            (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): FeedForwardBlock(\n",
       "              (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "              (1): GELU(approximate='none')\n",
       "              (2): Dropout(p=0.0, inplace=False)\n",
       "              (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            )\n",
       "            (2): Dropout(p=0.5, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): regression_Head(\n",
       "      (0): Reduce('b n e -> b e', 'mean')\n",
       "      (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): Linear(in_features=512, out_features=51, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'model with pos encoding'\n",
    "from MI_model_copy import modality_invariant_model\n",
    "\n",
    "model = modality_invariant_model()\n",
    "model.cuda()\n",
    "\n",
    "# rgb_data = torch.randn(16, 3, 480, 640).cuda()\n",
    "# depth_data = torch.randn(16, 3, 480, 640).cuda()\n",
    "# lidar_data = torch.randn(16, 1432, 3).cuda()\n",
    "# mmwave_data = torch.randn(16, 67, 5).cuda()\n",
    "# wifi_data = torch.randn(16, 3, 114, 10).cuda()\n",
    "# # modality_list = [False, False, False, False, False]\n",
    "# modality_list = [True, True, True, True, True]\n",
    "\n",
    "\n",
    "# out = model(rgb_data, depth_data,  mmwave_data, lidar_data, wifi_data, modality_list)\n",
    "\n",
    "# print(out.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, tensor_loader, criterion1, criterion2, device):\n",
    "    model.eval()\n",
    "    test_mpjpe = 0\n",
    "    test_pampjpe = 0\n",
    "    test_mse = 0\n",
    "    # random.seed(config['modality_existances']['val_random_seed'])\n",
    "    for data in tqdm(tensor_loader):\n",
    "        # start_time = time.time()\n",
    "        input_1, input_2, kpts, exist_list = data\n",
    "        input_1 = input_1.to(device)\n",
    "        input_2 = input_2.to(device)\n",
    "        kpts.to(device)\n",
    "        labels = kpts.type(torch.FloatTensor)\n",
    "        outputs = model(input_1, input_2, exist_list)\n",
    "        outputs = outputs.type(torch.FloatTensor)\n",
    "        outputs.to(device)\n",
    "        # t2 = time.time()\n",
    "        # forward_time = t2 - t1\n",
    "        test_mse += criterion1(outputs,labels).item() * input_1.size(0)\n",
    "\n",
    "        outputs = outputs.detach().numpy()\n",
    "        labels = labels.detach().numpy()\n",
    "        \n",
    "        mpjpe, pampjpe = criterion2(outputs,labels)\n",
    "        test_mpjpe += mpjpe.item() * input_1.size(0)\n",
    "        test_pampjpe += pampjpe.item() * input_1.size(0)\n",
    "        # t3 = time.time()\n",
    "        # record_time = t3 - t2\n",
    "        # print('load_time: ', load_time)\n",
    "        # print('forward_time: ', forward_time)\n",
    "        # print('record_time: ', record_time)\n",
    "    test_mpjpe = test_mpjpe/len(tensor_loader.dataset)\n",
    "    test_pampjpe = test_pampjpe/len(tensor_loader.dataset)\n",
    "    test_mse = test_mse/len(tensor_loader.dataset)\n",
    "    print(\"mse: {:.8f}, mpjpe: {:.8f}, pampjpe: {:.8f}\".format(float(test_mse), float(test_mpjpe),float(test_pampjpe)))\n",
    "    return test_mpjpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 39/3403 [00:12<18:28,  3.03it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CHEN_X~1\\AppData\\Local\\Temp/ipykernel_57168/3112677019.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_criterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_criterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\CHEN_X~1\\AppData\\Local\\Temp/ipykernel_57168/2048096793.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, tensor_loader, criterion1, criterion2, device)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtest_mse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# random.seed(config['modality_existances']['val_random_seed'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;31m# start_time = time.time()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkpts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexist_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\Desktop\\Modality_Invariant\\baseline\\syn_DI_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmod\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 \u001b[0mdata_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m                 \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\Desktop\\Modality_Invariant\\baseline\\syn_DI_dataset.py\u001b[0m in \u001b[0;36mread_frame\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_mod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'infra1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'infra2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rgb'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'depth'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# TODO: 深度和RGB的读取格式好像有区别？我忘了，待定\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_criterion = nn.MSELoss()\n",
    "test_criterion = error\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "test(model, val_loader, train_criterion, test_criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, num_epochs, learning_rate, train_criterion, test_criterion, device):\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        [\n",
    "                {'params': model.regression_head.parameters()}\n",
    "            ],\n",
    "        lr = learning_rate\n",
    "    )\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[20,40],gamma=0.1)\n",
    "    \"要改\"\n",
    "    parameter_dir = './baseline_weights/Dual/Depth_Wifi.pt'\n",
    "    best_test_mpjpe = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        # random.seed(epoch)\n",
    "        num_iter = 400\n",
    "        for i, data in enumerate(tqdm(train_loader)):\n",
    "            if i < num_iter:\n",
    "                input_1, input_2, kpts, exist_list = data\n",
    "                input_1 = input_1.to(device)\n",
    "                input_2 = input_2.to(device)\n",
    "                labels = kpts.to(device)\n",
    "                labels = labels.type(torch.FloatTensor)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(input_1, input_2, exist_list)\n",
    "                # print(outputs)\n",
    "                outputs = outputs.to(device)\n",
    "                outputs = outputs.type(torch.FloatTensor)\n",
    "                loss = train_criterion(outputs,labels)\n",
    "                if loss == float('nan'):\n",
    "                    print('nan')\n",
    "                    print(outputs)\n",
    "                    print(labels)\n",
    "                    \n",
    "                loss.backward()\n",
    "                # print(length)\n",
    "                # print(\"loss is \", loss.item())\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item() * input_1.size(0)\n",
    "            else:\n",
    "                break\n",
    "            # print(\"epoch loss is \", epoch_loss)\n",
    "        # epoch_loss = epoch_loss/len(train_loader.dataset)\n",
    "        \"要改\"\n",
    "        epoch_loss = epoch_loss/(input_1.size(0)*num_iter)\n",
    "        print('Epoch: {}, Loss: {:.8f}'.format(epoch, epoch_loss))\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            test_mpjpe = test(\n",
    "                model=model,\n",
    "                tensor_loader=test_loader,\n",
    "                criterion1 = train_criterion,\n",
    "                criterion2 = test_criterion,\n",
    "                device= device\n",
    "            )\n",
    "            # if test_mpjpe <= best_test_mpjpe:\n",
    "            #     print(f\"best test mpjpe is:{test_mpjpe}\")\n",
    "            #     best_test_mpjpe = test_mpjpe\n",
    "            #     torch.save(model.state_dict(), parameter_dir)\n",
    "        # scheduler.step()\n",
    "    torch.save(model.state_dict(), parameter_dir)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12991 [00:00<?, ?it/s]c:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "  3%|▎         | 400/12991 [18:28<9:41:41,  2.77s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.14043264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [17:11<9:01:17,  2.58s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.03195373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [16:04<8:26:00,  2.41s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.02368700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [11:28<6:01:16,  1.72s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.02039071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [09:30<4:59:17,  1.43s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.01743053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3403/3403 [27:38<00:00,  2.05it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01820512, mpjpe: 0.20873812, pampjpe: 0.09970371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [16:51<8:50:37,  2.53s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.01594987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [16:00<8:23:47,  2.40s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.01504485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [11:00<5:46:39,  1.65s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.01378055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [09:06<4:46:47,  1.37s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.01302622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [09:07<4:47:11,  1.37s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.01221796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3403/3403 [38:10<00:00,  1.49it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01396769, mpjpe: 0.18218196, pampjpe: 0.09106326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [18:08<9:30:56,  2.72s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.01214959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [13:49<7:15:25,  2.07s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.01156825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [11:02<5:47:22,  1.66s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.01167571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [09:35<5:02:01,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.01124495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [09:49<5:09:30,  1.47s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.01090582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3403/3403 [50:03<00:00,  1.13it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01288635, mpjpe: 0.17377144, pampjpe: 0.08831786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [11:20<5:57:02,  1.70s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 0.01055984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [10:38<5:35:09,  1.60s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.01067474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [09:43<5:06:18,  1.46s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.01025664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [10:20<5:25:26,  1.55s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Loss: 0.00992488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [14:37<7:40:12,  2.19s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Loss: 0.00979737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3403/3403 [47:58<00:00,  1.18it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01271662, mpjpe: 0.17256221, pampjpe: 0.08465823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [17:47<9:19:52,  2.67s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Loss: 0.00997791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [17:26<9:09:14,  2.62s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Loss: 0.00945736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [16:47<8:48:43,  2.52s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Loss: 0.00964044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [12:03<6:19:34,  1.81s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Loss: 0.00953991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [09:45<5:07:25,  1.46s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Loss: 0.00956479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3403/3403 [26:54<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01071178, mpjpe: 0.15740329, pampjpe: 0.08198752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [16:45<8:47:34,  2.51s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Loss: 0.00963128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [16:36<8:42:53,  2.49s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Loss: 0.00938930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [11:49<6:12:09,  1.77s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Loss: 0.00923315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [10:35<5:33:26,  1.59s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Loss: 0.00938686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [09:36<5:02:21,  1.44s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Loss: 0.00891433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3403/3403 [16:53<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01144655, mpjpe: 0.16269037, pampjpe: 0.08135050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [09:32<5:00:35,  1.43s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Loss: 0.00899003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [09:14<4:51:00,  1.39s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Loss: 0.00878520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [08:47<4:36:58,  1.32s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Loss: 0.00916615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [08:58<4:42:30,  1.35s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Loss: 0.00912729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 400/12991 [08:49<4:37:56,  1.32s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Loss: 0.00868466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3403/3403 [24:49<00:00,  2.29it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.01054933, mpjpe: 0.15550875, pampjpe: 0.08150853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_criterion = nn.MSELoss()\n",
    "test_criterion = error\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.load_state_dict(torch.load('./pre-train_weights/lidar_p1_random.pt'))\n",
    "model.to(device)\n",
    "train(\n",
    "    model=model,\n",
    "    train_loader= train_loader,\n",
    "     test_loader= val_loader,    \n",
    "    num_epochs= 35,\n",
    "    learning_rate=1e-3,\n",
    "    train_criterion = train_criterion,\n",
    "    test_criterion = test_criterion,\n",
    "    device=device \n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
