{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from torch import nn\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import yaml\n",
    "from evaluate import error\n",
    "from mmfi import make_dataset, make_dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loda Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S02 ['A01', 'A02', 'A03', 'A04', 'A06', 'A08', 'A09', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A26']\n",
      "S03 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A17', 'A18', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S05 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A19', 'A20', 'A21', 'A24', 'A25']\n",
      "S06 ['A01', 'A03', 'A04', 'A06', 'A07', 'A08', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A18', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S08 ['A01', 'A02', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A13', 'A14', 'A17', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S09 ['A01', 'A07', 'A08', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A17', 'A18', 'A20', 'A21', 'A24', 'A25', 'A27']\n",
      "S11 ['A01', 'A02', 'A03', 'A05', 'A06', 'A08', 'A10', 'A11', 'A12', 'A13', 'A16', 'A17', 'A18', 'A19', 'A21', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S12 ['A01', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A14', 'A15', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S13 ['A01', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A14', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A25', 'A26', 'A27']\n",
      "S14 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A13', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26']\n",
      "S15 ['A01', 'A02', 'A03', 'A04', 'A05', 'A07', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S16 ['A01', 'A04', 'A05', 'A06', 'A08', 'A09', 'A10', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A19', 'A20', 'A23', 'A24', 'A27']\n",
      "S17 ['A01', 'A02', 'A03', 'A04', 'A05', 'A08', 'A09', 'A10', 'A11', 'A13', 'A16', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S18 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A20', 'A21', 'A22', 'A23', 'A24', 'A26']\n",
      "S19 ['A01', 'A02', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A24', 'A25', 'A26', 'A27']\n",
      "S21 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A08', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A19', 'A20', 'A24', 'A25', 'A26', 'A27']\n",
      "S23 ['A01', 'A02', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A11', 'A12', 'A14', 'A16', 'A17', 'A19', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S25 ['A01', 'A02', 'A03', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A16', 'A17', 'A18', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S26 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A09', 'A10', 'A13', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A25', 'A27']\n",
      "S27 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A10', 'A11', 'A12', 'A13', 'A16', 'A17', 'A18', 'A19', 'A20', 'A22', 'A23', 'A25']\n",
      "S28 ['A01', 'A02', 'A03', 'A04', 'A05', 'A07', 'A08', 'A09', 'A11', 'A14', 'A15', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A25', 'A26', 'A27']\n",
      "S29 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A09', 'A12', 'A13', 'A14', 'A17', 'A18', 'A19', 'A20', 'A22', 'A23', 'A24', 'A25', 'A27']\n",
      "S30 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A21', 'A22', 'A24', 'A25', 'A26', 'A27']\n",
      "S31 ['A01', 'A02', 'A03', 'A04', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S32 ['A01', 'A02', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A19', 'A22', 'A25', 'A26', 'A27']\n",
      "S33 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26']\n",
      "S34 ['A01', 'A02', 'A03', 'A05', 'A06', 'A07', 'A08', 'A09', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S35 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A15', 'A16', 'A17', 'A18', 'A21', 'A23', 'A24', 'A26', 'A27']\n",
      "S36 ['A01', 'A02', 'A04', 'A05', 'A09', 'A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A23', 'A24', 'A26', 'A27']\n",
      "S37 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A24', 'A25', 'A26', 'A27']\n",
      "S38 ['A01', 'A03', 'A04', 'A05', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S40 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A27']\n",
      "S04 ['A02', 'A03', 'A06', 'A07', 'A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A26', 'A27']\n",
      "S07 ['A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26']\n",
      "S20 ['A02', 'A03', 'A05', 'A06', 'A07', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A21', 'A22', 'A23', 'A25', 'A26']\n",
      "S22 ['A02', 'A03', 'A05', 'A06', 'A07', 'A08', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S24 ['A02', 'A03', 'A04', 'A06', 'A07', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A27']\n",
      "S39 ['A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A20', 'A22', 'A23', 'A25', 'A26', 'A27']\n",
      "S01 ['A03', 'A06', 'A07', 'A08', 'A09', 'A10', 'A12', 'A13', 'A14', 'A15', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A24', 'A26', 'A27']\n",
      "S10 ['A03', 'A04', 'A08', 'A09', 'A10', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A23', 'A25', 'A26', 'A27']\n",
      "/n\n",
      "S01 ['A01', 'A02', 'A04', 'A05', 'A11', 'A16', 'A23', 'A25']\n",
      "S04 ['A01', 'A04', 'A05', 'A08', 'A09', 'A13', 'A25']\n",
      "S07 ['A01', 'A13', 'A18', 'A27']\n",
      "S10 ['A01', 'A02', 'A05', 'A06', 'A07', 'A11', 'A21', 'A22', 'A24']\n",
      "S20 ['A01', 'A04', 'A08', 'A09', 'A19', 'A20', 'A24', 'A27']\n",
      "S22 ['A01', 'A04', 'A09']\n",
      "S24 ['A01', 'A05', 'A08', 'A25', 'A26']\n",
      "S39 ['A01', 'A10', 'A19', 'A21', 'A24']\n",
      "S06 ['A02', 'A05', 'A09', 'A16', 'A17', 'A19', 'A20']\n",
      "S09 ['A02', 'A03', 'A04', 'A05', 'A06', 'A09', 'A16', 'A19', 'A22', 'A23', 'A26']\n",
      "S12 ['A02', 'A03', 'A13', 'A16']\n",
      "S13 ['A02', 'A12', 'A13', 'A15', 'A16', 'A24']\n",
      "S16 ['A02', 'A03', 'A07', 'A11', 'A18', 'A21', 'A22', 'A25', 'A26']\n",
      "S38 ['A02', 'A06', 'A17', 'A18']\n",
      "S08 ['A03', 'A12', 'A15', 'A16', 'A18']\n",
      "S19 ['A03', 'A14', 'A23']\n",
      "S23 ['A03', 'A10', 'A13', 'A15', 'A18', 'A20']\n",
      "S32 ['A03', 'A17', 'A18', 'A20', 'A21', 'A23', 'A24']\n",
      "S36 ['A03', 'A06', 'A07', 'A08', 'A13', 'A21', 'A22', 'A25']\n",
      "S11 ['A04', 'A07', 'A09', 'A14', 'A15', 'A20', 'A22']\n",
      "S25 ['A04', 'A15', 'A19']\n",
      "S34 ['A04', 'A10', 'A11', 'A12']\n",
      "S02 ['A05', 'A07', 'A10', 'A17', 'A25', 'A27']\n",
      "S31 ['A05', 'A06', 'A17']\n",
      "S15 ['A06', 'A08']\n",
      "S17 ['A06', 'A07', 'A12', 'A14', 'A15', 'A17']\n",
      "S28 ['A06', 'A10', 'A12', 'A13', 'A16', 'A24']\n",
      "S21 ['A07', 'A09', 'A18', 'A21', 'A22', 'A23']\n",
      "S26 ['A07', 'A08', 'A11', 'A12', 'A14', 'A24', 'A26']\n",
      "S05 ['A08', 'A17', 'A18', 'A22', 'A23', 'A26', 'A27']\n",
      "S29 ['A08', 'A10', 'A11', 'A15', 'A16', 'A21', 'A26']\n",
      "S27 ['A09', 'A14', 'A15', 'A21', 'A24', 'A26', 'A27']\n",
      "S30 ['A10', 'A11', 'A20', 'A23']\n",
      "S40 ['A10', 'A26']\n",
      "S37 ['A11', 'A23']\n",
      "S14 ['A12', 'A14', 'A27']\n",
      "S18 ['A12', 'A19', 'A25', 'A27']\n",
      "S03 ['A13', 'A14', 'A19', 'A20']\n",
      "S35 ['A14', 'A19', 'A20', 'A22', 'A25']\n",
      "S33 ['A17', 'A27']\n"
     ]
    }
   ],
   "source": [
    "dataset_root = 'd:\\Data\\My_MMFi_Data\\MMFi_Dataset'\n",
    "# xian zai shi yong de shi Radar_Fused\n",
    "with open('config_copy_a.yaml', 'r') as fd:\n",
    "    config = yaml.load(fd, Loader=yaml.FullLoader)\n",
    "\n",
    "train_dataset, val_dataset = make_dataset(dataset_root, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    Padds batch of variable length\n",
    "\n",
    "    note: it converts things ToTensor manually here since the ToTensor transform\n",
    "    assume it takes in images rather than arbitrary tensors.\n",
    "\n",
    "    dict_keys(['modality', 'scene', 'subject', 'action', 'idx', 'output', \n",
    "    'input_rgb', 'input_depth', 'input_lidar', 'input_mmwave'])\n",
    "    '''\n",
    "    ## get sequence lengths\n",
    "    # for t in batch:\n",
    "    #     print(t.keys())\n",
    "    #     print(a)\n",
    "    # #     # print(t[0].shape,t[1].shape)\n",
    "    # kpts = []\n",
    "    # [kpts.append(np.array(t['output'])) for t in batch]\n",
    "    # kpts = torch.FloatTensor(np.array(kpts))\n",
    "\n",
    "    # lengths = torch.tensor([t['input_rgb'].shape[0] for t in batch ])\n",
    "    all_actions = {'A01': 0., 'A02': 1., 'A03': 2., 'A04': 3., 'A05': 4., \n",
    "                'A06': 5., 'A07': 6., 'A08': 7., 'A09': 8., 'A10': 9.,\n",
    "                'A11': 10., 'A12': 11., 'A13': 12., 'A14': 13., 'A15': 14., \n",
    "                'A16': 15., 'A17': 16., 'A18': 17., 'A19': 18., 'A20': 19., \n",
    "                'A21': 20., 'A22': 21., 'A23': 22., 'A24': 23., 'A25': 24., \n",
    "                'A26': 25., 'A27': 26.}\n",
    "    \n",
    "    labels = []\n",
    "    [labels.append(all_actions[t['action']]) for t in batch]\n",
    "    labels = torch.FloatTensor(labels)\n",
    "\n",
    "    # rgb\n",
    "    # rgb_data = np.array([(t['input_rgb']) for t in batch ])\n",
    "    # rgb_data = torch.FloatTensor(rgb_data).permute(0,3,1,2)\n",
    "\n",
    "    # # depth\n",
    "    depth_data = np.array([(t['input_depth']) for t in batch ])\n",
    "    depth_data = torch.FloatTensor(depth_data).permute(0,3,1,2)\n",
    "\n",
    "    # # mmwave\n",
    "    # ## padd\n",
    "    # mmwave_data = [torch.Tensor(t['input_mmwave']) for t in batch ]\n",
    "    # mmwave_data = torch.nn.utils.rnn.pad_sequence(mmwave_data)\n",
    "    # ## compute mask\n",
    "    # mmwave_data = mmwave_data.permute(1,0,2)\n",
    "\n",
    "    # # lidar\n",
    "    # ## padd\n",
    "    # lidar_data = [torch.Tensor(t['input_lidar']) for t in batch ]\n",
    "    # lidar_data = torch.nn.utils.rnn.pad_sequence(lidar_data)\n",
    "    # ## compute mask\n",
    "    # lidar_data = lidar_data.permute(1,0,2)\n",
    "\n",
    "    # # wifi-csi\n",
    "    # wifi_data = np.array([(t['input_wifi-csi']) for t in batch ])\n",
    "    # wifi_data = torch.FloatTensor(wifi_data)\n",
    "\n",
    "    # return rgb_data, depth_data, lidar_data, mmwave_data, wifi_data, kpts, lengths\n",
    "    return depth_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_generator = torch.manual_seed(config['init_rand_seed'])\n",
    "train_loader = make_dataloader(train_dataset, is_training=True, generator=rng_generator, **config['loader'], collate_fn = collate_fn_padd)\n",
    "val_loader = make_dataloader(val_dataset, is_training=False, generator=rng_generator, **config['loader'], collate_fn = collate_fn_padd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 480, 640]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    # rgb_data, depth_data, lidar_data, mmwave_data, wifi_data, kpts, lengths = data\n",
    "    # print(rgb_data[0].shape, depth_data[0].shape, lidar_data[0].shape, mmwave_data[0].shape, wifi_data[0].shape,kpts.shape, lengths.shape)\n",
    "    # print(rgb_data.shape, depth_data.shape, lidar_data.shape, mmwave_data.shape, wifi_data.shape, kpts.shape, lengths.shape)\n",
    "    depth_data, label = data\n",
    "    print(depth_data.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 27])\n"
     ]
    }
   ],
   "source": [
    "from HAR_depth_benchmark.depth_ResNet18 import *\n",
    "\n",
    "model = Depth_ResNet18()\n",
    "\n",
    "out = model(depth_data)\n",
    "print(out.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, tensor_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_acc = 0\n",
    "    test_loss = 0\n",
    "    for data in tqdm(tensor_loader):\n",
    "        rgb_data, labels = data\n",
    "        inputs = rgb_data.to(device)\n",
    "        labels.to(device)\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.type(torch.FloatTensor)\n",
    "        outputs.to(device)\n",
    "        loss = criterion(outputs,labels)\n",
    "        predict_y = torch.argmax(outputs,dim=1).to(device)\n",
    "        accuracy = (predict_y == labels.to(device)).sum().item()\n",
    "        test_acc += accuracy\n",
    "        test_loss += loss.item() * labels.size(0)\n",
    "    test_acc = test_acc/len(tensor_loader.dataset)\n",
    "    test_loss = test_loss/len(tensor_loader.dataset)\n",
    "    print(\"validation accuracy:{:.4f}, loss:{:.5f}\".format(float(test_acc),float(test_loss)))\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, num_epochs, learning_rate, criterion, device):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[20,40],gamma=0.1)\n",
    "    parameter_dir = './HAR_depth_benchmark/depth_Resnet18.pt'\n",
    "    best_test_acc = 0.4518\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        for data in tqdm(train_loader):\n",
    "            rgb_data, labels = data\n",
    "            inputs = rgb_data.to(device)\n",
    "            labels.to(device)\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.type(torch.FloatTensor)\n",
    "            outputs.to(device)\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            # print(length)\n",
    "            # print(\"loss is \", loss.item())\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * labels.size(0)\n",
    "            predict_y = torch.argmax(outputs,dim=1).to(device)\n",
    "            epoch_accuracy += (predict_y == labels.to(device)).sum().item()\n",
    "            # print(\"epoch loss is \", epoch_loss)\n",
    "        epoch_loss = epoch_loss/len(train_loader.dataset)\n",
    "        epoch_accuracy = epoch_accuracy/len(train_loader.dataset)\n",
    "        print('Epoch:{}, Accuracy:{:.4f},Loss:{:.9f}'.format(epoch+1, float(epoch_accuracy),float(epoch_loss)))\n",
    "        if (epoch+1) % 3 == 0:\n",
    "            test_acc = test(\n",
    "                model=model,\n",
    "                tensor_loader=test_loader,\n",
    "                criterion = criterion,\n",
    "                device= device\n",
    "            )\n",
    "            if test_acc >= best_test_acc:\n",
    "                print(f\"best test acuracy is:{test_acc}\")\n",
    "                best_test_acc = test_acc\n",
    "                torch.save(model.state_dict(), parameter_dir)\n",
    "        # scheduler.step()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8019/8019 [5:33:34<00:00,  2.50s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Accuracy:0.9828,Loss:0.055348533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8019/8019 [5:04:14<00:00,  2.28s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2, Accuracy:0.9861,Loss:0.045155051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8019/8019 [3:42:01<00:00,  1.66s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3, Accuracy:0.9878,Loss:0.038957103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2005/2005 [20:06<00:00,  1.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:0.4643, loss:3.43889\n",
      "best test acuracy is:0.46430352911834394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 373/8019 [12:21<4:13:23,  1.99s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CHEN_X~1\\AppData\\Local\\Temp/ipykernel_9896/1607526724.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# model.load_state_dict(torch.load('./RGB_benchmark/rgb_ResNet18/RGB_Resnet18.pt'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m train(\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\CHEN_X~1\\AppData\\Local\\Temp/ipykernel_9896/2045632354.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, test_loader, num_epochs, learning_rate, criterion, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mepoch_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mrgb_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrgb_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\Desktop\\Modality_Invariant\\HAR\\mmfi.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    282\u001b[0m                 \u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmod\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m                     \u001b[0mdata_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m                     \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\Desktop\\Modality_Invariant\\HAR\\mmfi.py\u001b[0m in \u001b[0;36mread_frame\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'depth'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# TODO: 深度和RGB的读取格式好像有区别？我忘了，待定\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'lidar'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criteria = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.load_state_dict(torch.load('./RGB_benchmark/rgb_ResNet18/RGB_Resnet18.pt'))\n",
    "model.to(device)\n",
    "train(\n",
    "    model=model, \n",
    "    train_loader= train_loader,\n",
    "    test_loader= val_loader,    \n",
    "    num_epochs= 50,\n",
    "    learning_rate=1e-3,\n",
    "    criterion = criteria,\n",
    "    device=device \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2005/2005 [25:09<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy:0.4518, loss:3.11546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45177079436338696"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(\n",
    "        model=model,\n",
    "        tensor_loader=val_loader,\n",
    "        criterion = criteria,\n",
    "        device= device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dir = './HAR_depth_benchmark/depth_Resnet18.pt'\n",
    "torch.save(model.state_dict(), parameter_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
