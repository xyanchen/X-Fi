{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "from torch import nn\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import yaml\n",
    "from evaluate import error\n",
    "from mmfi import make_dataset, make_dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loda Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Data\\MMFi_Dataset\\E01\\S02\\A01\\depth frame007.png\n"
     ]
    }
   ],
   "source": [
    "dir = 'd:\\\\Data\\\\MMFi_Dataset\\\\E01\\\\S02\\\\A01\\\\depth\\\\frame007.png'\n",
    "_mod, _frame = os.path.split(dir)\n",
    "print(_mod, _frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S02 ['A01', 'A02', 'A03', 'A04', 'A06', 'A08', 'A09', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A26']\n",
      "S03 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A15', 'A16', 'A17', 'A18', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S05 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A19', 'A20', 'A21', 'A24', 'A25']\n",
      "S06 ['A01', 'A03', 'A04', 'A06', 'A07', 'A08', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A18', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S08 ['A01', 'A02', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A13', 'A14', 'A17', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S09 ['A01', 'A07', 'A08', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A17', 'A18', 'A20', 'A21', 'A24', 'A25', 'A27']\n",
      "S11 ['A01', 'A02', 'A03', 'A05', 'A06', 'A08', 'A10', 'A11', 'A12', 'A13', 'A16', 'A17', 'A18', 'A19', 'A21', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S12 ['A01', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A14', 'A15', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S13 ['A01', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A14', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A25', 'A26', 'A27']\n",
      "S14 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A13', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26']\n",
      "S15 ['A01', 'A02', 'A03', 'A04', 'A05', 'A07', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S16 ['A01', 'A04', 'A05', 'A06', 'A08', 'A09', 'A10', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A19', 'A20', 'A23', 'A24', 'A27']\n",
      "S17 ['A01', 'A02', 'A03', 'A04', 'A05', 'A08', 'A09', 'A10', 'A11', 'A13', 'A16', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S18 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A20', 'A21', 'A22', 'A23', 'A24', 'A26']\n",
      "S19 ['A01', 'A02', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A24', 'A25', 'A26', 'A27']\n",
      "S21 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A08', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A19', 'A20', 'A24', 'A25', 'A26', 'A27']\n",
      "S23 ['A01', 'A02', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A11', 'A12', 'A14', 'A16', 'A17', 'A19', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S25 ['A01', 'A02', 'A03', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A16', 'A17', 'A18', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S26 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A09', 'A10', 'A13', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A25', 'A27']\n",
      "S27 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A10', 'A11', 'A12', 'A13', 'A16', 'A17', 'A18', 'A19', 'A20', 'A22', 'A23', 'A25']\n",
      "S28 ['A01', 'A02', 'A03', 'A04', 'A05', 'A07', 'A08', 'A09', 'A11', 'A14', 'A15', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A25', 'A26', 'A27']\n",
      "S29 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A09', 'A12', 'A13', 'A14', 'A17', 'A18', 'A19', 'A20', 'A22', 'A23', 'A24', 'A25', 'A27']\n",
      "S30 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A21', 'A22', 'A24', 'A25', 'A26', 'A27']\n",
      "S31 ['A01', 'A02', 'A03', 'A04', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S32 ['A01', 'A02', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A19', 'A22', 'A25', 'A26', 'A27']\n",
      "S33 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26']\n",
      "S34 ['A01', 'A02', 'A03', 'A05', 'A06', 'A07', 'A08', 'A09', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S35 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A15', 'A16', 'A17', 'A18', 'A21', 'A23', 'A24', 'A26', 'A27']\n",
      "S36 ['A01', 'A02', 'A04', 'A05', 'A09', 'A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A23', 'A24', 'A26', 'A27']\n",
      "S37 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A24', 'A25', 'A26', 'A27']\n",
      "S38 ['A01', 'A03', 'A04', 'A05', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S40 ['A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A27']\n",
      "S04 ['A02', 'A03', 'A06', 'A07', 'A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A26', 'A27']\n",
      "S07 ['A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A10', 'A11', 'A12', 'A14', 'A15', 'A16', 'A17', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26']\n",
      "S20 ['A02', 'A03', 'A05', 'A06', 'A07', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A21', 'A22', 'A23', 'A25', 'A26']\n",
      "S22 ['A02', 'A03', 'A05', 'A06', 'A07', 'A08', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A25', 'A26', 'A27']\n",
      "S24 ['A02', 'A03', 'A04', 'A06', 'A07', 'A09', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A23', 'A24', 'A27']\n",
      "S39 ['A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A09', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A20', 'A22', 'A23', 'A25', 'A26', 'A27']\n",
      "S01 ['A03', 'A06', 'A07', 'A08', 'A09', 'A10', 'A12', 'A13', 'A14', 'A15', 'A17', 'A18', 'A19', 'A20', 'A21', 'A22', 'A24', 'A26', 'A27']\n",
      "S10 ['A03', 'A04', 'A08', 'A09', 'A10', 'A12', 'A13', 'A14', 'A15', 'A16', 'A17', 'A18', 'A19', 'A20', 'A23', 'A25', 'A26', 'A27']\n",
      "/n\n",
      "S01 ['A01', 'A02', 'A04', 'A05', 'A11', 'A16', 'A23', 'A25']\n",
      "S04 ['A01', 'A04', 'A05', 'A08', 'A09', 'A13', 'A25']\n",
      "S07 ['A01', 'A13', 'A18', 'A27']\n",
      "S10 ['A01', 'A02', 'A05', 'A06', 'A07', 'A11', 'A21', 'A22', 'A24']\n",
      "S20 ['A01', 'A04', 'A08', 'A09', 'A19', 'A20', 'A24', 'A27']\n",
      "S22 ['A01', 'A04', 'A09']\n",
      "S24 ['A01', 'A05', 'A08', 'A25', 'A26']\n",
      "S39 ['A01', 'A10', 'A19', 'A21', 'A24']\n",
      "S06 ['A02', 'A05', 'A09', 'A16', 'A17', 'A19', 'A20']\n",
      "S09 ['A02', 'A03', 'A04', 'A05', 'A06', 'A09', 'A16', 'A19', 'A22', 'A23', 'A26']\n",
      "S12 ['A02', 'A03', 'A13', 'A16']\n",
      "S13 ['A02', 'A12', 'A13', 'A15', 'A16', 'A24']\n",
      "S16 ['A02', 'A03', 'A07', 'A11', 'A18', 'A21', 'A22', 'A25', 'A26']\n",
      "S38 ['A02', 'A06', 'A17', 'A18']\n",
      "S08 ['A03', 'A12', 'A15', 'A16', 'A18']\n",
      "S19 ['A03', 'A14', 'A23']\n",
      "S23 ['A03', 'A10', 'A13', 'A15', 'A18', 'A20']\n",
      "S32 ['A03', 'A17', 'A18', 'A20', 'A21', 'A23', 'A24']\n",
      "S36 ['A03', 'A06', 'A07', 'A08', 'A13', 'A21', 'A22', 'A25']\n",
      "S11 ['A04', 'A07', 'A09', 'A14', 'A15', 'A20', 'A22']\n",
      "S25 ['A04', 'A15', 'A19']\n",
      "S34 ['A04', 'A10', 'A11', 'A12']\n",
      "S02 ['A05', 'A07', 'A10', 'A17', 'A25', 'A27']\n",
      "S31 ['A05', 'A06', 'A17']\n",
      "S15 ['A06', 'A08']\n",
      "S17 ['A06', 'A07', 'A12', 'A14', 'A15', 'A17']\n",
      "S28 ['A06', 'A10', 'A12', 'A13', 'A16', 'A24']\n",
      "S21 ['A07', 'A09', 'A18', 'A21', 'A22', 'A23']\n",
      "S26 ['A07', 'A08', 'A11', 'A12', 'A14', 'A24', 'A26']\n",
      "S05 ['A08', 'A17', 'A18', 'A22', 'A23', 'A26', 'A27']\n",
      "S29 ['A08', 'A10', 'A11', 'A15', 'A16', 'A21', 'A26']\n",
      "S27 ['A09', 'A14', 'A15', 'A21', 'A24', 'A26', 'A27']\n",
      "S30 ['A10', 'A11', 'A20', 'A23']\n",
      "S40 ['A10', 'A26']\n",
      "S37 ['A11', 'A23']\n",
      "S14 ['A12', 'A14', 'A27']\n",
      "S18 ['A12', 'A19', 'A25', 'A27']\n",
      "S03 ['A13', 'A14', 'A19', 'A20']\n",
      "S35 ['A14', 'A19', 'A20', 'A22', 'A25']\n",
      "S33 ['A17', 'A27']\n"
     ]
    }
   ],
   "source": [
    "dataset_root = 'd:\\Data\\My_MMFi_Data\\MMFi_Dataset'\n",
    "# xian zai shi yong de shi Radar_Fused\n",
    "with open('config.yaml', 'r') as fd:\n",
    "    config = yaml.load(fd, Loader=yaml.FullLoader)\n",
    "\n",
    "train_dataset, val_dataset = make_dataset(dataset_root, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_padd(batch):\n",
    "    '''\n",
    "    Padds batch of variable length\n",
    "\n",
    "    note: it converts things ToTensor manually here since the ToTensor transform\n",
    "    assume it takes in images rather than arbitrary tensors.\n",
    "\n",
    "    dict_keys(['modality', 'scene', 'subject', 'action', 'idx', 'output', \n",
    "    'input_rgb', 'input_depth', 'input_lidar', 'input_mmwave'])\n",
    "    '''\n",
    "    ## get sequence lengths\n",
    "    # for t in batch:\n",
    "    #     print(t.keys())\n",
    "    #     print(a)\n",
    "    # #     # print(t[0].shape,t[1].shape)\n",
    "    kpts = []\n",
    "    [kpts.append(np.array(t['output'])) for t in batch]\n",
    "    kpts = torch.FloatTensor(np.array(kpts))\n",
    "\n",
    "    lengths = torch.tensor([t['input_depth'].shape[0] for t in batch ])\n",
    "\n",
    "    # # rgb\n",
    "    # rgb_data = np.array([(t['input_rgb']) for t in batch ])\n",
    "    # rgb_data = torch.FloatTensor(rgb_data).permute(0,3,1,2)\n",
    "\n",
    "    # depth\n",
    "    depth_data = np.array([(t['input_depth']) for t in batch ])\n",
    "    depth_data = torch.FloatTensor(depth_data).permute(0,3,1,2)\n",
    "\n",
    "    # # mmwave\n",
    "    # ## padd\n",
    "    # mmwave_data = [torch.Tensor(t['input_mmwave']) for t in batch ]\n",
    "    # mmwave_data = torch.nn.utils.rnn.pad_sequence(mmwave_data)\n",
    "    # ## compute mask\n",
    "    # mmwave_data = mmwave_data.permute(1,0,2)\n",
    "\n",
    "    # # lidar\n",
    "    # ## padd\n",
    "    # lidar_data = [torch.Tensor(t['input_lidar']) for t in batch ]\n",
    "    # lidar_data = torch.nn.utils.rnn.pad_sequence(lidar_data)\n",
    "    # ## compute mask\n",
    "    # lidar_data = lidar_data.permute(1,0,2)\n",
    "\n",
    "    # # wifi-csi\n",
    "    # wifi_data = np.array([(t['input_wifi-csi']) for t in batch ])\n",
    "    # wifi_data = torch.FloatTensor(wifi_data)\n",
    "\n",
    "    # return rgb_data, depth_data, lidar_data, mmwave_data, wifi_data, kpts, lengths\n",
    "    return depth_data, kpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_generator = torch.manual_seed(config['init_rand_seed'])\n",
    "train_loader = make_dataloader(train_dataset, is_training=True, generator=rng_generator, **config['loader'], collate_fn = collate_fn_padd)\n",
    "val_loader = make_dataloader(val_dataset, is_training=False, generator=rng_generator, **config['loader'], collate_fn = collate_fn_padd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8019 2005\n",
      "torch.Size([32, 3, 480, 640]) torch.Size([32, 17, 3])\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader), len(val_loader))\n",
    "for i, data in enumerate(train_loader):\n",
    "    # rgb_data, depth_data, lidar_data, mmwave_data, wifi_data, kpts, lengths = data\n",
    "    # print(rgb_data[0].shape, depth_data[0].shape, lidar_data[0].shape, mmwave_data[0].shape, wifi_data[0].shape,kpts.shape, lengths.shape)\n",
    "    # print(rgb_data.shape, depth_data.shape, lidar_data.shape, mmwave_data.shape, wifi_data.shape, kpts.shape, lengths.shape)\n",
    "    depth_data, label = data\n",
    "    print(depth_data.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from depth_benchmark.depth_ResNet18 import *\n",
    "\n",
    "model = Depth_ResNet18()\n",
    "\n",
    "# x = torch.randn(32, 100, 5, 3)\n",
    "# all_domain_kpts, all_domain_outputs = model(x)\n",
    "# print(all_domain_kpts[0].shape, all_domain_outputs[1][4].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, tensor_loader, criterion1, criterion2, device):\n",
    "    model.eval()\n",
    "    test_mpjpe = 0\n",
    "    test_pampjpe = 0\n",
    "    test_mse = 0\n",
    "    for i, data in enumerate(tensor_loader):\n",
    "        depth_data, kpts = data\n",
    "        inputs = depth_data.to(device)\n",
    "        kpts.to(device)\n",
    "        labels = kpts.type(torch.FloatTensor)\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.type(torch.FloatTensor)\n",
    "        outputs.to(device)\n",
    "        test_mse += criterion1(outputs,labels).item() * inputs.size(0)\n",
    "\n",
    "        outputs = outputs.detach().numpy()\n",
    "        labels = labels.detach().numpy()\n",
    "        \n",
    "        mpjpe, pampjpe = criterion2(outputs,labels)\n",
    "        test_mpjpe += mpjpe.item() * inputs.size(0)\n",
    "        test_pampjpe += pampjpe.item() * inputs.size(0)\n",
    "        if i > 10:\n",
    "            break\n",
    "    test_mpjpe = test_mpjpe/len(tensor_loader.dataset)\n",
    "    test_pampjpe = test_pampjpe/len(tensor_loader.dataset)\n",
    "    test_mse = test_mse/len(tensor_loader.dataset)\n",
    "    print(\"mse: {:.8f}, mpjpe: {:.8f}, pampjpe: {:.8f}\".format(float(test_mse), float(test_mpjpe),float(test_pampjpe)))\n",
    "    return test_mpjpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, num_epochs, learning_rate, train_criterion, test_criterion, device):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[20,40],gamma=0.1)\n",
    "    parameter_dir = './depth_benchmark/depth_Resnet18.pt'\n",
    "    best_test_mpjpe = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            depth_data, kpts = data\n",
    "            inputs = depth_data.to(device)\n",
    "            labels = kpts.to(device)\n",
    "            labels = labels.type(torch.FloatTensor)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.to(device)\n",
    "            outputs = outputs.type(torch.FloatTensor)\n",
    "            loss = train_criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            # print(length)\n",
    "            # print(\"loss is \", loss.item())\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "            # print(\"epoch loss is \", epoch_loss)\n",
    "            if i > 10:\n",
    "                break   \n",
    "        epoch_loss = epoch_loss/len(train_loader.dataset)\n",
    "        print('Epoch: {}, Loss: {:.8f}'.format(epoch, epoch_loss))\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            test_mpjpe = test(\n",
    "                model=model,\n",
    "                tensor_loader=test_loader,\n",
    "                criterion1 = train_criterion,\n",
    "                criterion2 = test_criterion,\n",
    "                device= device\n",
    "            )\n",
    "            if test_mpjpe <= best_test_mpjpe:\n",
    "                print(f\"best test mpjpe is:{test_mpjpe}\")\n",
    "                best_test_mpjpe = test_mpjpe\n",
    "                torch.save(model.state_dict(), parameter_dir)\n",
    "        # scheduler.step()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.00190598\n",
      "Epoch: 1, Loss: 0.00015393\n",
      "Epoch: 2, Loss: 0.00007392\n",
      "Epoch: 3, Loss: 0.00005242\n",
      "Epoch: 4, Loss: 0.00004551\n",
      "mse: 0.00013087, mpjpe: 0.00143339, pampjpe: 0.00070077\n",
      "best test mpjpe is:0.0014333886121451847\n",
      "Epoch: 5, Loss: 0.00004022\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CHEN_X~1\\AppData\\Local\\Temp/ipykernel_7220/1589644188.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# model.load_state_dict(torch.load('./pre-train_weights/lidar_p1_random.pt'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m train(\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\CHEN_X~1\\AppData\\Local\\Temp/ipykernel_7220/2995960836.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, test_loader, num_epochs, learning_rate, train_criterion, test_criterion, device)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mepoch_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mdepth_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkpts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdepth_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\Desktop\\Modality_Invariant\\mmfi.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    278\u001b[0m                 \u001b[0mdata_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmod\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m                     \u001b[0mdata_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m                     \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_mod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Chen_Xinyan\\Desktop\\Modality_Invariant\\mmfi.py\u001b[0m in \u001b[0;36mread_frame\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'depth'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# TODO: 深度和RGB的读取格式好像有区别？我忘了，待定\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'lidar'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_criterion = nn.MSELoss()\n",
    "test_criterion = error\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.load_state_dict(torch.load('./pre-train_weights/lidar_p1_random.pt'))\n",
    "model.to(device)\n",
    "train(\n",
    "    model=model, \n",
    "    train_loader= train_loader,\n",
    "    test_loader= val_loader,    \n",
    "    num_epochs= 50,\n",
    "    learning_rate=1e-3,\n",
    "    train_criterion = train_criterion,\n",
    "    test_criterion = test_criterion,\n",
    "    device=device \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
